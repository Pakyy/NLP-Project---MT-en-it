{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5TthqyECVen"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF7SX4xJCe6n",
        "outputId": "b8633009-e1fb-477f-cea6-28631a7cc1a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting it-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.7.0/it_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement translate-toolki (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for translate-toolki\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: translate-toolkit in /usr/local/lib/python3.10/dist-packages (3.14.5)\n",
            "Requirement already satisfied: cwcwidth>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from translate-toolkit) (0.1.9)\n",
            "Requirement already satisfied: lxml>=4.6.3 in /usr/local/lib/python3.10/dist-packages (from translate-toolkit) (5.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Requirement already satisfied: comet-ml in /usr/local/lib/python3.10/dist-packages (3.47.6)\n",
            "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (5.9.5)\n",
            "Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (6.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.32.3)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.19.2)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.19.3)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.2.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.17.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.1.1)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (0.22.7)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (13.9.4)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.22.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
            "Requirement already satisfied: unbabel-comet in /usr/local/lib/python3.10/dist-packages (2.2.4)\n",
            "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.27.0)\n",
            "Requirement already satisfied: jsonargparse==3.13.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (3.13.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (4.25.5)\n",
            "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.5.0.post0)\n",
            "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.5.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.10.3)\n",
            "Requirement already satisfied: transformers<5.0,>=4.17 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (4.47.1)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2024.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.11.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (5.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.4.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.11.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.18.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download it_core_news_sm\n",
        "!pip install translate-toolki\n",
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install translate-toolkit\n",
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install sacrebleu\n",
        "!pip install rouge-score\n",
        "!pip install comet-ml\n",
        "!pip install unbabel-comet\n",
        "!pip install datasets\n",
        "\n",
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WwViX7fCgFG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from translate.storage import tmx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import re\n",
        "import logging\n",
        "import string\n",
        "import nltk\n",
        "import gc\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "import evaluate\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoConfig,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    LlamaTokenizer,\n",
        "    LlamaForCausalLM,\n",
        "    LlamaConfig,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    TrainerCallback\n",
        ")\n",
        "from datasets import Dataset, load_dataset, DatasetDict\n",
        "from huggingface_hub import notebook_login, login\n",
        "from google.colab import output\n",
        "from sacrebleu.metrics import BLEU\n",
        "from bitsandbytes.optim import Adam8bit\n",
        "import sacrebleu\n",
        "from rouge_score import rouge_scorer\n",
        "from comet import download_model, load_from_checkpoint\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOIuwlu3Chys",
        "outputId": "e2004ad7-481d-424e-b5e7-b5692dcb93b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/MyDrive/en-it.tmx\"\n",
        "sentence_pairs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BL-gg68CjHJ"
      },
      "outputs": [],
      "source": [
        "from comet import load_from_checkpoint, download_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnxGe_bnCkRK"
      },
      "outputs": [],
      "source": [
        "token = \"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\"\n",
        "login(token)  # Enter your token when prompted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2hNR6LvCmhp"
      },
      "outputs": [],
      "source": [
        "CUDA_LAUNCH_BLOCKING=1\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEak6h94Cnhx"
      },
      "outputs": [],
      "source": [
        "# Open the file in read mode\n",
        "with open(file_path, 'rb') as f:\n",
        "  tmx_file = tmx.tmxfile(f)\n",
        "\n",
        "# Iterate through the translation units and store sentence pairs\n",
        "for unit in tmx_file.units:\n",
        "    source_text = unit.source\n",
        "    target_text = unit.target\n",
        "    sentence_pairs.append((source_text, target_text))\n",
        "\n",
        "# Create a DataFrame from the sentence pairs\n",
        "df = pd.DataFrame(sentence_pairs, columns=['Source', 'Target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "si6GIJVpCosz",
        "outputId": "3468596b-5bdf-4532-be1a-cee26271347a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source          0\n",
            "Target          0\n",
            "Source_clean    0\n",
            "Target_clean    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df[['Source_clean', 'Target_clean']]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Source_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"We know that right We ve experienced that\",\n          \"fish health mission blue oceans science\",\n          \"And bringing those two together might seem a very daunting task but what I m going to try to say is that even in that complexity there s some simple themes that I think if we understand we can really move forward\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Lo sappiamo tutti giusto Ci siamo passati tutti\",\n          \"fish health mission blue oceans science\",\n          \"E mettere insieme queste due cose pu\\u00f2 sembrare un lavoro molto complicato Ma quello che vorrei cercare di comunicare \\u00e8 che anche in quella complessit\\u00e0 esistono aspetti semplici che io credo se riusciamo a comprendere ci aiutano a fare grandi passi avanti\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-651211d8-4a7c-4f63-b570-eddcfc5a97ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source_clean</th>\n",
              "      <th>Target_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>There s a tight and surprising link between th...</td>\n",
              "      <td>Esiste uno stretto e sorprendente legame tra l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fish health mission blue oceans science</td>\n",
              "      <td>fish health mission blue oceans science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stephen Palumbi Following the mercury trail</td>\n",
              "      <td>Stephen Palumbi Sulle tracce del mercurio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>It can be a very complicated thing the ocean</td>\n",
              "      <td>Può essere una cosa davvero complicata l oceano</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>And it can be a very complicated thing what hu...</td>\n",
              "      <td>E può essere una cosa davvero complicata la sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>And bringing those two together might seem a v...</td>\n",
              "      <td>E mettere insieme queste due cose può sembrare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>And those simple themes aren t really themes a...</td>\n",
              "      <td>E questi semplici aspetti non riguardano le co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>And I m going to start with this one If momma ...</td>\n",
              "      <td>E vorrei partire da questa mamma infelice tutt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>We know that right We ve experienced that</td>\n",
              "      <td>Lo sappiamo tutti giusto Ci siamo passati tutti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>And if we just take that and we build from the...</td>\n",
              "      <td>E se prendiamo questa idea e partiamo da qui p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-651211d8-4a7c-4f63-b570-eddcfc5a97ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-651211d8-4a7c-4f63-b570-eddcfc5a97ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-651211d8-4a7c-4f63-b570-eddcfc5a97ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b74c0db-a77b-4fdf-b9e0-adb008fc4896\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b74c0db-a77b-4fdf-b9e0-adb008fc4896')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b74c0db-a77b-4fdf-b9e0-adb008fc4896 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         Source_clean  \\\n",
              "1   There s a tight and surprising link between th...   \n",
              "2             fish health mission blue oceans science   \n",
              "4         Stephen Palumbi Following the mercury trail   \n",
              "5        It can be a very complicated thing the ocean   \n",
              "6   And it can be a very complicated thing what hu...   \n",
              "7   And bringing those two together might seem a v...   \n",
              "8   And those simple themes aren t really themes a...   \n",
              "9   And I m going to start with this one If momma ...   \n",
              "10          We know that right We ve experienced that   \n",
              "11  And if we just take that and we build from the...   \n",
              "\n",
              "                                         Target_clean  \n",
              "1   Esiste uno stretto e sorprendente legame tra l...  \n",
              "2             fish health mission blue oceans science  \n",
              "4           Stephen Palumbi Sulle tracce del mercurio  \n",
              "5     Può essere una cosa davvero complicata l oceano  \n",
              "6   E può essere una cosa davvero complicata la sa...  \n",
              "7   E mettere insieme queste due cose può sembrare...  \n",
              "8   E questi semplici aspetti non riguardano le co...  \n",
              "9   E vorrei partire da questa mamma infelice tutt...  \n",
              "10    Lo sappiamo tutti giusto Ci siamo passati tutti  \n",
              "11  E se prendiamo questa idea e partiamo da qui p...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Funzione di pulizia per rimuovere caratteri speciali e gestire gli accenti\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-zA-ZàèéìòùÀÈÉÌÒÙçÇ]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "# Applichiamo la pulizia su Source e Target\n",
        "df['Source_clean'] = df['Source'].apply(clean_text)\n",
        "df['Target_clean'] = df['Target'].apply(clean_text)\n",
        "\n",
        "# Rimuove le righe con frasi vuote\n",
        "df = df[df['Source_clean'].str.strip() != '']\n",
        "df = df[df['Target_clean'].str.strip() != '']\n",
        "\n",
        "# Rimuove frasi troppo corte (esempio: meno di 3 parole)\n",
        "df = df[df['Source_clean'].apply(lambda x: len(x.split()) >= 3)]\n",
        "df = df[df['Target_clean'].apply(lambda x: len(x.split()) >= 3)]\n",
        "\n",
        "# Verifica la presenza di eventuali valori nulli\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Rimozione duplicati\n",
        "df.drop_duplicates(subset=['Source_clean', 'Target_clean'], inplace=True)\n",
        "\n",
        "# Verifica dei risultati puliti\n",
        "df[['Source_clean', 'Target_clean']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ASwQD-MCpn9",
        "outputId": "cbe96356-c04b-4073-b645-58fef8058715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset length after the removal of too long sentences: 153535\n"
          ]
        }
      ],
      "source": [
        "# Rimuove frasi troppo lunghe (più di 96 parole)\n",
        "df = df[df['Source'].apply(lambda x: len(x.split()) <= 96)]\n",
        "df = df[df['Target'].apply(lambda x: len(x.split()) <= 96)]\n",
        "# Stampa la lunghezza del dataset\n",
        "print(f\"Dataset length after the removal of too long sentences: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tXTtDmbCq3X",
        "outputId": "6c63633d-b46d-4f5c-f75e-8e59ed1c0111"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(76768, 4)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sample dataset for performance purposes\n",
        "df = df.sample(frac=0.5, random_state=42)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj6KhAx4Cr5C"
      },
      "outputs": [],
      "source": [
        "df[['Source_clean', 'Target_clean']].to_csv('preprocessed_data.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYtvtLBfCtpA"
      },
      "source": [
        "# TOKENIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti-BiIO3ON2i"
      },
      "outputs": [],
      "source": [
        "model_path = \"meta-llama/Llama-3.2-1B-Instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrUV0tGJCv0G"
      },
      "outputs": [],
      "source": [
        "\n",
        "TARGET_LANGUAGE_CODE = \"it\"\n",
        "START_SYMBOL_SOURCE = \"<START_SYMBOL_source>\"\n",
        "END_SYMBOL_SOURCE = \"<END_SYMBOL_SOURCE>\"\n",
        "START_SYMBOL_TARGET = \"<START_SYMBOL_TARGET>\"\n",
        "END_SYMBOL_TARGET = \"<END_SYMBOL_TARGET>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jAIQqy2CwIB"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('csv', data_files='/content/preprocessed_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FYIgsizCy4r",
        "outputId": "c913e50f-d087-4fe8-93f5-2e438287f0db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Source_clean', 'Target_clean'],\n",
              "        num_rows: 61414\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Source_clean', 'Target_clean'],\n",
              "        num_rows: 15354\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = dataset['train'].train_test_split(test_size=0.2)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEWz00oZHHvi"
      },
      "source": [
        "#TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9dy5SZwDhSm",
        "outputId": "1fd604da-1fab-4b0e-e996-5592b5e98a9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Define special tokens\n",
        "special_tokens = {\n",
        "    \"additional_special_tokens\": [\n",
        "        START_SYMBOL_SOURCE, END_SYMBOL_SOURCE, START_SYMBOL_TARGET, END_SYMBOL_TARGET\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Add a padding token if not already present\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# Add the special tokens to the tokenizer\n",
        "tokenizer.add_special_tokens(special_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "d2bf1514b32049bba3c97ff225f9074b",
            "1884cae8803345b191f4f8f6b1138183",
            "22831f605ab04246b866e3e4c027f776",
            "1ce23bf27af4446eb91732da254e965b",
            "4bb9cdb483b7464bae0d11fb72e3cb10",
            "964fe078759241c2849baa34a82c83a4",
            "dd3fa43beb2640c49475d461054641ec",
            "8bddd00754db45bcac5acd0476aa0159",
            "086ec1c12e964affb6bcb44631013028",
            "1a5acdf599f6471d8c047ca27a297c3a",
            "4d0650d624524d3693c06361edb43f5f",
            "1af0c4bb91bb42c6aeec5baf9b9ed02f",
            "84b71fff553d40f58073c373bffa06e7",
            "81ff3ea51258414cbfb8b94d4d4b0be4",
            "91c0cf6011a24ab8bbf75635811bfccb",
            "3f54a15789ba472c8018e32302d342e4",
            "de565f0a80a14205a3b1650e0a64169a",
            "8114e680bc3a4acc874aa64e57d7d8d3",
            "d181b3359ec04d81a0cad9785c54a404",
            "0c94ccd47e5d4497ac86b65159e07057",
            "c7bdb4f48463433e8aa1c8fce3fadb18",
            "c71e90b5ca284c62896cd62d057b3135"
          ]
        },
        "id": "nTYeTJ7OBzbU",
        "outputId": "6cb3c416-4172-4e9a-9c94-ac8528e77604"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2bf1514b32049bba3c97ff225f9074b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/61414 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1af0c4bb91bb42c6aeec5baf9b9ed02f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15354 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'Source_clean': 'art computers design film technology visualizations',\n",
              " 'Target_clean': 'art computers design film technology visualizations',\n",
              " 'combined_text': '<START_SYMBOL_source> art computers design film technology visualizations <END_SYMBOL_SOURCE> <START_SYMBOL_TARGET> art computers design film technology visualizations <END_SYMBOL_TARGET>'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def process(example):\n",
        "  sources = example[\"Source_clean\"]\n",
        "  targets = example[\"Target_clean\"]\n",
        "  combined_text = [\n",
        "    f\"{START_SYMBOL_SOURCE} {source} {END_SYMBOL_SOURCE} \"\n",
        "    f\"{START_SYMBOL_TARGET} {target} {END_SYMBOL_TARGET}\"\n",
        "    for source, target in zip(sources, targets)\n",
        "  ]\n",
        "  return {'combined_text':combined_text}\n",
        "\n",
        "dataset = dataset.map(process, batched=True)\n",
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "0010651988784254b4af63b4faf935d0",
            "579d97ee2a83449a8d45d0f497034c80",
            "a464133b7d4e444eaaecaa75d32f5817",
            "55cceec0a9454eb78a5784f0388e70d8",
            "40b0acd17a48459194710c3036220571",
            "0f87676e7a8f48249bb894f46e1c56e4",
            "9f7c2b4c7d494eec9f21d58546990742",
            "abb6b9497e0249459f1bbead92b138bd",
            "beb1b0ba09c1447a919eea6212ea0638",
            "ebe5abfee92f4beb9f496134eeac9f4d",
            "259e92d2889d4c94a6d4a7871f5c2131",
            "866f9d582a5a4c798972e03a8079e99a",
            "f9fed312d06645648c04d775b0a3a5ca",
            "fbb4ab6f91dd4e7e89bbe73ca4969ad1",
            "3b604a484cb24db4a128f80cf1f323c7",
            "0be5e33e7fbe4bbf8a11aa1033dbbd6d",
            "5671049a33aa408080e0f9141ac4126c",
            "981cc9bd46cf4b13b2efedbbcbf4902e",
            "221615f928384afbbc9b196045b0612c",
            "822848f990c44910a4887e2f1e67fd39",
            "b40fcdefdf264425b308339178ef2d59",
            "9adf48897e754158a6c485007ae23f69"
          ]
        },
        "id": "k2X3DnABDWZv",
        "outputId": "4244aec3-5e47-4618-d961-71b921c3c8a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0010651988784254b4af63b4faf935d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/61414 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "866f9d582a5a4c798972e03a8079e99a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15354 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': [128000,\n",
              "  128257,\n",
              "  1989,\n",
              "  19002,\n",
              "  2955,\n",
              "  4632,\n",
              "  5557,\n",
              "  9302,\n",
              "  8200,\n",
              "  220,\n",
              "  128258,\n",
              "  220,\n",
              "  128259,\n",
              "  1989,\n",
              "  19002,\n",
              "  2955,\n",
              "  4632,\n",
              "  5557,\n",
              "  9302,\n",
              "  8200,\n",
              "  220,\n",
              "  128260],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(lambda examples: tokenizer(examples['combined_text']), batched=True)\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"Target_clean\", \"Source_clean\",\"combined_text\"])\n",
        "tokenized_dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaVCwYhJHNar"
      },
      "source": [
        "# SETUP MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDFmkwkpJCWW",
        "outputId": "519a9f90-3e2e-4916-f727-769a4ddb6a25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Embedding(128261, 2048)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "config = AutoConfig.from_pretrained(model_path)\n",
        "config.num_hidden_layers = 6  # Use only the first 6 layers\n",
        "\n",
        "# Resize the model's token embeddings to accommodate the new tokens\n",
        "model = AutoModelForCausalLM.from_config(config)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J4JxqwgIk2A",
        "outputId": "10230c04-3309-4bff-c9d2-e34c5a9ca158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Parameters: 627,609,600\n",
            "Trainable Parameters: 627,609,600\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'Total Parameters: {total_params:,}')\n",
        "    print(f'Trainable Parameters: {trainable_params:,}')\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyu1c_LY5dpU"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer,\n",
        "                                                mlm = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pELwldkp5mJG",
        "outputId": "5638e43a-368c-4e48-9979-914a95d0d56e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "comet_ml is installed but the Comet API Key is not configured. Please set the `COMET_API_KEY` environment variable to enable Comet logging. Check out the documentation for other ways of configuring it: https://www.comet.com/docs/v2/guides/experiment-management/configure-sdk/#set-the-api-key\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/llama-translation2\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    #save_steps=20,\n",
        "    logging_steps=500,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=64,\n",
        "    gradient_checkpointing = True,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    fp16=True,  # Mixed precision for faster training\n",
        "    push_to_hub=False,\n",
        "    max_grad_norm=0.1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYHRbwNM_diP"
      },
      "outputs": [],
      "source": [
        "class ClearMemoryCallback(TrainerCallback):\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        print(f\"Clearing GPU memory after epoch {state.epoch}...\")\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "# Inside callbacks\n",
        "class StateCallback(TrainerCallback):\n",
        "    def on_epoch_end(self, args, state, control, metrics=None, **kwargs):\n",
        "        logging.info(f\"Epoch {state.epoch} ended.\")\n",
        "        if metrics:\n",
        "            logging.info(f\"Metrics: {metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiO5YyzoHR1B"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZTM1XmN9d6C",
        "outputId": "ddfc9444-1b3d-4f0a-ccb7-84b1cd722a1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-25-0769bccad51c>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "optimizer = Adam8bit(model.parameters(), lr=5e-5)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['test'],\n",
        "    tokenizer = tokenizer,\n",
        "    optimizers=(optimizer, None)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "aPYttWMJDKd6",
        "outputId": "9a83d49f-90c9-41a0-eff0-fb8c9d375af4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2390' max='2390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2390/2390 11:37:20, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.515500</td>\n",
              "      <td>4.321095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.616100</td>\n",
              "      <td>3.922055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.464800</td>\n",
              "      <td>4.158695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.561500</td>\n",
              "      <td>4.387391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2390, training_loss=3.144602857773274, metrics={'train_runtime': 41859.1212, 'train_samples_per_second': 14.672, 'train_steps_per_second': 0.057, 'total_flos': 1.1169961479212237e+17, 'train_loss': 3.144602857773274, 'epoch': 9.996222482740654})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stlKVTwoFHfZ"
      },
      "source": [
        "# EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzhpeClCPn_3"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(sentence, model, tokenizer, max_length=512, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    # Move model to the specified device\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Format input text\n",
        "        input_text = f\"{START_SYMBOL_SOURCE} {sentence} {END_SYMBOL_SOURCE} {START_SYMBOL_TARGET}\"\n",
        "\n",
        "        # Tokenize and move inputs to the same device as the model\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Generate translation\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_beams=5,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        # Decode the generated tokens\n",
        "        translated_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return translated_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a0b9716165994bdb9784c462ff4a728a",
            "9e9f435cd9024be4b3ebd35ae636a9e7",
            "bc3f96343c5a456d99dcea0d61b7d144",
            "b6324fef12d048689eed48fac8d713b6"
          ]
        },
        "id": "2vMpB2iywRjv",
        "outputId": "562dcc6d-0093-486d-ea67-3f946e4466c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating Predictions:   0%|          | 0/500 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   0%|          | 1/500 [00:05<45:51,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   0%|          | 2/500 [00:10<44:48,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   1%|          | 3/500 [00:14<37:14,  4.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   1%|          | 4/500 [00:17<32:53,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   1%|          | 5/500 [00:20<30:30,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   1%|          | 6/500 [00:24<29:42,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   1%|▏         | 7/500 [00:27<28:21,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   2%|▏         | 8/500 [00:30<27:19,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   2%|▏         | 9/500 [00:31<22:45,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   2%|▏         | 10/500 [00:34<22:51,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   2%|▏         | 11/500 [00:38<24:36,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   2%|▏         | 12/500 [00:41<24:47,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   3%|▎         | 13/500 [00:44<24:15,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   3%|▎         | 14/500 [00:46<23:25,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   3%|▎         | 15/500 [00:49<23:34,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   3%|▎         | 16/500 [00:51<21:43,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   3%|▎         | 17/500 [00:55<22:54,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   4%|▎         | 18/500 [00:58<24:29,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   4%|▍         | 19/500 [01:01<23:55,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   4%|▍         | 20/500 [01:04<22:42,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   4%|▍         | 21/500 [01:07<23:44,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   4%|▍         | 22/500 [01:09<20:57,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   5%|▍         | 23/500 [01:12<22:27,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   5%|▍         | 24/500 [01:14<21:18,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   5%|▌         | 25/500 [01:17<22:20,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   5%|▌         | 26/500 [01:20<20:29,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   5%|▌         | 27/500 [01:23<22:14,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   6%|▌         | 28/500 [01:26<23:03,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   6%|▌         | 29/500 [01:29<23:30,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   6%|▌         | 30/500 [01:32<22:39,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   6%|▌         | 31/500 [01:36<24:29,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   6%|▋         | 32/500 [01:38<23:18,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   7%|▋         | 33/500 [01:41<23:37,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   7%|▋         | 34/500 [01:44<23:46,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   7%|▋         | 35/500 [01:46<19:37,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   7%|▋         | 36/500 [01:49<21:44,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   7%|▋         | 37/500 [01:52<22:36,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   8%|▊         | 38/500 [01:54<19:50,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   8%|▊         | 39/500 [01:57<20:27,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   8%|▊         | 40/500 [01:59<18:53,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   8%|▊         | 41/500 [02:02<19:57,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   8%|▊         | 42/500 [02:06<22:17,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   9%|▊         | 43/500 [02:08<21:20,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   9%|▉         | 44/500 [02:10<20:05,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   9%|▉         | 45/500 [02:13<19:25,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   9%|▉         | 46/500 [02:16<20:25,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:   9%|▉         | 47/500 [02:19<22:25,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  10%|▉         | 48/500 [02:22<22:17,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  10%|▉         | 49/500 [02:25<21:40,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  10%|█         | 50/500 [02:29<24:15,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  10%|█         | 51/500 [02:33<25:25,  3.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  10%|█         | 52/500 [02:36<25:39,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  11%|█         | 53/500 [02:39<23:59,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  11%|█         | 54/500 [02:42<22:45,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  11%|█         | 55/500 [02:45<22:57,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  11%|█         | 56/500 [02:49<24:47,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  11%|█▏        | 57/500 [02:52<24:27,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  12%|█▏        | 58/500 [02:55<22:51,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  12%|█▏        | 59/500 [02:58<22:17,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  12%|█▏        | 60/500 [03:00<20:04,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  12%|█▏        | 61/500 [03:03<21:20,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  12%|█▏        | 62/500 [03:06<21:36,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  13%|█▎        | 63/500 [03:09<22:28,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  13%|█▎        | 64/500 [03:13<22:33,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  13%|█▎        | 65/500 [03:15<21:53,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  13%|█▎        | 66/500 [03:19<23:30,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  13%|█▎        | 67/500 [03:22<22:57,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  14%|█▎        | 68/500 [03:24<20:43,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  14%|█▍        | 69/500 [03:28<21:31,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  14%|█▍        | 70/500 [03:31<22:12,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  14%|█▍        | 71/500 [03:34<22:03,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  14%|█▍        | 72/500 [03:37<21:40,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  15%|█▍        | 73/500 [03:40<20:49,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  15%|█▍        | 74/500 [03:43<20:34,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  15%|█▌        | 75/500 [03:46<21:55,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  15%|█▌        | 76/500 [03:49<22:07,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  15%|█▌        | 77/500 [03:53<22:25,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  16%|█▌        | 78/500 [03:54<18:54,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  16%|█▌        | 79/500 [03:57<19:49,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  16%|█▌        | 80/500 [04:01<21:27,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  16%|█▌        | 81/500 [04:04<20:28,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  16%|█▋        | 82/500 [04:07<20:55,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  17%|█▋        | 83/500 [04:10<20:47,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  17%|█▋        | 84/500 [04:13<21:32,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  17%|█▋        | 85/500 [04:17<22:32,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  17%|█▋        | 86/500 [04:20<22:12,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  17%|█▋        | 87/500 [04:23<22:05,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  18%|█▊        | 88/500 [04:26<21:05,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  18%|█▊        | 89/500 [04:29<22:19,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  18%|█▊        | 90/500 [04:32<20:06,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  18%|█▊        | 91/500 [04:35<20:04,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  18%|█▊        | 92/500 [04:38<20:24,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  19%|█▊        | 93/500 [04:40<19:48,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  19%|█▉        | 94/500 [04:43<19:12,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  19%|█▉        | 95/500 [04:46<19:21,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  19%|█▉        | 96/500 [04:49<19:23,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  19%|█▉        | 97/500 [04:52<20:01,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  20%|█▉        | 98/500 [04:55<19:48,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  20%|█▉        | 99/500 [04:59<21:29,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  20%|██        | 100/500 [05:02<21:12,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  20%|██        | 101/500 [05:05<21:04,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  20%|██        | 102/500 [05:08<19:40,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  21%|██        | 103/500 [05:11<20:08,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  21%|██        | 104/500 [05:15<21:44,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  21%|██        | 105/500 [05:17<20:36,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  21%|██        | 106/500 [05:21<20:54,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  21%|██▏       | 107/500 [05:24<20:36,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  22%|██▏       | 108/500 [05:26<18:04,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  22%|██▏       | 109/500 [05:29<19:52,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  22%|██▏       | 110/500 [05:33<20:08,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  22%|██▏       | 111/500 [05:35<17:53,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  22%|██▏       | 112/500 [05:38<19:01,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  23%|██▎       | 113/500 [05:41<19:48,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  23%|██▎       | 114/500 [05:44<18:25,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  23%|██▎       | 115/500 [05:47<19:03,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  23%|██▎       | 116/500 [05:50<19:11,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  23%|██▎       | 117/500 [05:51<15:59,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  24%|██▎       | 118/500 [05:55<17:50,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  24%|██▍       | 119/500 [05:59<19:37,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  24%|██▍       | 120/500 [06:01<18:31,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  24%|██▍       | 121/500 [06:04<19:13,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  24%|██▍       | 122/500 [06:07<19:02,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  25%|██▍       | 123/500 [06:11<19:53,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  25%|██▍       | 124/500 [06:11<14:10,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  25%|██▌       | 125/500 [06:14<16:18,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  25%|██▌       | 126/500 [06:17<15:59,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  25%|██▌       | 127/500 [06:20<16:26,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  26%|██▌       | 128/500 [06:23<17:30,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  26%|██▌       | 129/500 [06:26<17:03,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  26%|██▌       | 130/500 [06:29<17:59,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  26%|██▌       | 131/500 [06:32<17:49,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  26%|██▋       | 132/500 [06:35<17:38,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  27%|██▋       | 133/500 [06:38<18:02,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  27%|██▋       | 134/500 [06:41<18:53,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  27%|██▋       | 135/500 [06:45<19:53,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  27%|██▋       | 136/500 [06:48<19:00,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  27%|██▋       | 137/500 [06:51<18:40,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  28%|██▊       | 138/500 [06:54<19:05,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  28%|██▊       | 139/500 [06:57<18:53,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  28%|██▊       | 140/500 [07:00<18:55,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  28%|██▊       | 141/500 [07:03<18:05,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  28%|██▊       | 142/500 [07:05<16:57,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  29%|██▊       | 143/500 [07:09<17:27,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  29%|██▉       | 144/500 [07:11<16:55,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  29%|██▉       | 145/500 [07:14<17:27,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  29%|██▉       | 146/500 [07:17<16:40,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  29%|██▉       | 147/500 [07:20<16:37,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  30%|██▉       | 148/500 [07:23<17:33,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  30%|██▉       | 149/500 [07:27<18:42,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  30%|███       | 150/500 [07:29<17:47,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  30%|███       | 151/500 [07:32<15:55,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  30%|███       | 152/500 [07:34<15:39,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  31%|███       | 153/500 [07:37<16:05,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  31%|███       | 154/500 [07:40<16:27,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  31%|███       | 155/500 [07:43<17:03,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  31%|███       | 156/500 [07:46<16:58,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  31%|███▏      | 157/500 [07:49<17:15,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  32%|███▏      | 158/500 [07:53<17:27,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  32%|███▏      | 159/500 [07:56<18:18,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  32%|███▏      | 160/500 [07:59<17:31,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  32%|███▏      | 161/500 [08:01<15:59,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  32%|███▏      | 162/500 [08:03<14:23,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  33%|███▎      | 163/500 [08:06<14:38,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  33%|███▎      | 164/500 [08:09<15:31,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  33%|███▎      | 165/500 [08:12<15:45,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  33%|███▎      | 166/500 [08:13<12:15,  2.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  33%|███▎      | 167/500 [08:16<13:24,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  34%|███▎      | 168/500 [08:19<14:14,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  34%|███▍      | 169/500 [08:21<14:41,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  34%|███▍      | 170/500 [08:24<15:13,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  34%|███▍      | 171/500 [08:28<16:12,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  34%|███▍      | 172/500 [08:30<15:21,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  35%|███▍      | 173/500 [08:33<15:46,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  35%|███▍      | 174/500 [08:36<15:32,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  35%|███▌      | 175/500 [08:39<15:55,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  35%|███▌      | 176/500 [08:42<15:37,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  35%|███▌      | 177/500 [08:44<14:12,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  36%|███▌      | 178/500 [08:47<14:49,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  36%|███▌      | 179/500 [08:50<15:17,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  36%|███▌      | 180/500 [08:53<15:44,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  36%|███▌      | 181/500 [08:57<15:59,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  36%|███▋      | 182/500 [09:00<16:06,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  37%|███▋      | 183/500 [09:03<16:32,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  37%|███▋      | 184/500 [09:06<16:34,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  37%|███▋      | 185/500 [09:07<13:24,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  37%|███▋      | 186/500 [09:11<15:00,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  37%|███▋      | 187/500 [09:14<15:28,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  38%|███▊      | 188/500 [09:17<14:26,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  38%|███▊      | 189/500 [09:20<15:10,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  38%|███▊      | 190/500 [09:24<16:37,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  38%|███▊      | 191/500 [09:27<16:38,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  38%|███▊      | 192/500 [09:29<15:07,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  39%|███▊      | 193/500 [09:32<15:29,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  39%|███▉      | 194/500 [09:35<14:56,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  39%|███▉      | 195/500 [09:39<16:07,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  39%|███▉      | 196/500 [09:41<14:59,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  39%|███▉      | 197/500 [09:45<15:16,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  40%|███▉      | 198/500 [09:48<15:30,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  40%|███▉      | 199/500 [09:49<13:15,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  40%|████      | 200/500 [09:53<14:35,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  40%|████      | 201/500 [09:55<13:36,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  40%|████      | 202/500 [09:58<13:38,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  41%|████      | 203/500 [10:01<13:44,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  41%|████      | 204/500 [10:04<14:44,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  41%|████      | 205/500 [10:08<15:12,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  41%|████      | 206/500 [10:10<14:31,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  41%|████▏     | 207/500 [10:14<14:56,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  42%|████▏     | 208/500 [10:16<13:44,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  42%|████▏     | 209/500 [10:19<14:31,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  42%|████▏     | 210/500 [10:23<15:09,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  42%|████▏     | 211/500 [10:26<15:23,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  42%|████▏     | 212/500 [10:29<15:15,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  43%|████▎     | 213/500 [10:32<14:25,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  43%|████▎     | 214/500 [10:36<15:19,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  43%|████▎     | 215/500 [10:39<15:59,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  43%|████▎     | 216/500 [10:42<15:22,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  43%|████▎     | 217/500 [10:44<13:50,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  44%|████▎     | 218/500 [10:46<12:29,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  44%|████▍     | 219/500 [10:49<12:48,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  44%|████▍     | 220/500 [10:51<11:50,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  44%|████▍     | 221/500 [10:54<12:14,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  44%|████▍     | 222/500 [10:57<12:29,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  45%|████▍     | 223/500 [11:00<12:48,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  45%|████▍     | 224/500 [11:03<13:26,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  45%|████▌     | 225/500 [11:07<13:49,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  45%|████▌     | 226/500 [11:09<13:28,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  45%|████▌     | 227/500 [11:13<13:44,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  46%|████▌     | 228/500 [11:14<11:51,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  46%|████▌     | 229/500 [11:18<12:46,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  46%|████▌     | 230/500 [11:21<14:01,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  46%|████▌     | 231/500 [11:24<13:46,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  46%|████▋     | 232/500 [11:27<13:32,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  47%|████▋     | 233/500 [11:30<13:36,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  47%|████▋     | 234/500 [11:33<13:21,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  47%|████▋     | 235/500 [11:37<14:00,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  47%|████▋     | 236/500 [11:40<14:04,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  47%|████▋     | 237/500 [11:43<14:09,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  48%|████▊     | 238/500 [11:47<14:09,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  48%|████▊     | 239/500 [11:50<13:57,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  48%|████▊     | 240/500 [11:53<13:16,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  48%|████▊     | 241/500 [11:55<12:49,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  48%|████▊     | 242/500 [11:58<12:51,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  49%|████▊     | 243/500 [12:02<13:21,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  49%|████▉     | 244/500 [12:06<14:10,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  49%|████▉     | 245/500 [12:09<13:59,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  49%|████▉     | 246/500 [12:12<13:31,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  49%|████▉     | 247/500 [12:15<13:24,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  50%|████▉     | 248/500 [12:18<13:34,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  50%|████▉     | 249/500 [12:20<11:59,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  50%|█████     | 250/500 [12:22<11:06,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  50%|█████     | 251/500 [12:25<11:16,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  50%|█████     | 252/500 [12:28<10:39,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  51%|█████     | 253/500 [12:31<11:24,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  51%|█████     | 254/500 [12:33<11:06,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  51%|█████     | 255/500 [12:36<11:09,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  51%|█████     | 256/500 [12:39<11:34,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  51%|█████▏    | 257/500 [12:41<10:13,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  52%|█████▏    | 258/500 [12:44<11:05,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  52%|█████▏    | 259/500 [12:47<11:35,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  52%|█████▏    | 260/500 [12:51<11:53,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  52%|█████▏    | 261/500 [12:54<12:06,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  52%|█████▏    | 262/500 [12:57<11:41,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  53%|█████▎    | 263/500 [13:00<11:38,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  53%|█████▎    | 264/500 [13:03<12:38,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  53%|█████▎    | 265/500 [13:06<12:21,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  53%|█████▎    | 266/500 [13:09<11:55,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  53%|█████▎    | 267/500 [13:12<11:56,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  54%|█████▎    | 268/500 [13:16<12:22,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  54%|█████▍    | 269/500 [13:19<12:32,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  54%|█████▍    | 270/500 [13:22<11:31,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  54%|█████▍    | 271/500 [13:23<09:57,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  54%|█████▍    | 272/500 [13:26<10:19,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  55%|█████▍    | 273/500 [13:29<10:21,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  55%|█████▍    | 274/500 [13:32<10:29,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  55%|█████▌    | 275/500 [13:34<09:52,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  55%|█████▌    | 276/500 [13:36<08:41,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  55%|█████▌    | 277/500 [13:39<09:37,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  56%|█████▌    | 278/500 [13:42<10:14,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  56%|█████▌    | 279/500 [13:46<11:03,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  56%|█████▌    | 280/500 [13:49<11:26,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  56%|█████▌    | 281/500 [13:52<11:24,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  56%|█████▋    | 282/500 [13:55<11:21,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  57%|█████▋    | 283/500 [13:59<11:13,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  57%|█████▋    | 284/500 [14:02<11:35,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  57%|█████▋    | 285/500 [14:04<10:39,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  57%|█████▋    | 286/500 [14:07<10:28,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  57%|█████▋    | 287/500 [14:10<10:24,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  58%|█████▊    | 288/500 [14:13<09:54,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  58%|█████▊    | 289/500 [14:16<10:43,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  58%|█████▊    | 290/500 [14:19<10:21,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  58%|█████▊    | 291/500 [14:22<10:22,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  58%|█████▊    | 292/500 [14:25<10:30,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  59%|█████▊    | 293/500 [14:29<11:08,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  59%|█████▉    | 294/500 [14:31<10:19,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  59%|█████▉    | 295/500 [14:34<09:34,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  59%|█████▉    | 296/500 [14:37<09:42,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  59%|█████▉    | 297/500 [14:40<09:45,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  60%|█████▉    | 298/500 [14:43<09:55,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  60%|█████▉    | 299/500 [14:45<09:02,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  60%|██████    | 300/500 [14:48<09:43,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  60%|██████    | 301/500 [14:51<09:40,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  60%|██████    | 302/500 [14:54<09:00,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  61%|██████    | 303/500 [14:57<09:52,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  61%|██████    | 304/500 [15:00<09:58,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  61%|██████    | 305/500 [15:04<10:13,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  61%|██████    | 306/500 [15:06<09:46,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  61%|██████▏   | 307/500 [15:08<08:24,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  62%|██████▏   | 308/500 [15:11<08:25,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  62%|██████▏   | 309/500 [15:14<09:18,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  62%|██████▏   | 310/500 [15:17<09:22,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  62%|██████▏   | 311/500 [15:21<09:29,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  62%|██████▏   | 312/500 [15:24<09:45,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  63%|██████▎   | 313/500 [15:25<07:56,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  63%|██████▎   | 314/500 [15:29<09:05,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  63%|██████▎   | 315/500 [15:32<08:55,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  63%|██████▎   | 316/500 [15:35<09:10,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  63%|██████▎   | 317/500 [15:38<08:52,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  64%|██████▎   | 318/500 [15:41<09:10,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  64%|██████▍   | 319/500 [15:45<09:46,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  64%|██████▍   | 320/500 [15:48<09:47,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  64%|██████▍   | 321/500 [15:51<09:37,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  64%|██████▍   | 322/500 [15:54<09:35,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  65%|██████▍   | 323/500 [15:58<09:30,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  65%|██████▍   | 324/500 [16:00<08:58,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  65%|██████▌   | 325/500 [16:03<08:48,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  65%|██████▌   | 326/500 [16:07<09:01,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  65%|██████▌   | 327/500 [16:10<09:16,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  66%|██████▌   | 328/500 [16:12<08:07,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  66%|██████▌   | 329/500 [16:15<08:32,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  66%|██████▌   | 330/500 [16:18<07:47,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  66%|██████▌   | 331/500 [16:21<08:14,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  66%|██████▋   | 332/500 [16:24<08:37,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  67%|██████▋   | 333/500 [16:28<09:01,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  67%|██████▋   | 334/500 [16:31<09:01,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  67%|██████▋   | 335/500 [16:34<08:55,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  67%|██████▋   | 336/500 [16:38<09:09,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  67%|██████▋   | 337/500 [16:40<07:47,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  68%|██████▊   | 338/500 [16:43<08:13,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  68%|██████▊   | 339/500 [16:47<08:22,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  68%|██████▊   | 340/500 [16:50<08:16,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  68%|██████▊   | 341/500 [16:53<08:06,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  68%|██████▊   | 342/500 [16:56<08:37,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  69%|██████▊   | 343/500 [16:59<08:19,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  69%|██████▉   | 344/500 [17:02<07:53,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  69%|██████▉   | 345/500 [17:05<07:28,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  69%|██████▉   | 346/500 [17:08<07:53,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  69%|██████▉   | 347/500 [17:12<08:24,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  70%|██████▉   | 348/500 [17:15<08:20,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  70%|██████▉   | 349/500 [17:18<07:45,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  70%|███████   | 350/500 [17:20<07:04,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  70%|███████   | 351/500 [17:23<07:26,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  70%|███████   | 352/500 [17:25<06:36,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  71%|███████   | 353/500 [17:27<05:49,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  71%|███████   | 354/500 [17:30<06:04,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  71%|███████   | 355/500 [17:33<06:12,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  71%|███████   | 356/500 [17:35<06:25,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  71%|███████▏  | 357/500 [17:39<07:11,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  72%|███████▏  | 358/500 [17:42<06:45,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  72%|███████▏  | 359/500 [17:45<06:56,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  72%|███████▏  | 360/500 [17:47<06:15,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  72%|███████▏  | 361/500 [17:50<06:39,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  72%|███████▏  | 362/500 [17:54<07:03,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  73%|███████▎  | 363/500 [17:57<07:21,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  73%|███████▎  | 364/500 [18:01<07:16,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  73%|███████▎  | 365/500 [18:04<07:15,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  73%|███████▎  | 366/500 [18:07<07:01,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  73%|███████▎  | 367/500 [18:10<07:11,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  74%|███████▎  | 368/500 [18:13<06:51,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  74%|███████▍  | 369/500 [18:15<06:20,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  74%|███████▍  | 370/500 [18:18<06:10,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  74%|███████▍  | 371/500 [18:22<06:34,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  74%|███████▍  | 372/500 [18:25<06:43,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  75%|███████▍  | 373/500 [18:28<06:36,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  75%|███████▍  | 374/500 [18:31<06:23,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  75%|███████▌  | 375/500 [18:34<06:32,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  75%|███████▌  | 376/500 [18:38<06:41,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  75%|███████▌  | 377/500 [18:41<06:32,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  76%|███████▌  | 378/500 [18:44<06:23,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  76%|███████▌  | 379/500 [18:47<06:13,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  76%|███████▌  | 380/500 [18:50<06:20,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  76%|███████▌  | 381/500 [18:53<06:12,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  76%|███████▋  | 382/500 [18:56<05:58,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  77%|███████▋  | 383/500 [18:59<05:58,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  77%|███████▋  | 384/500 [19:02<05:56,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  77%|███████▋  | 385/500 [19:06<06:01,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  77%|███████▋  | 386/500 [19:09<06:11,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  77%|███████▋  | 387/500 [19:12<05:58,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  78%|███████▊  | 388/500 [19:14<05:19,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  78%|███████▊  | 389/500 [19:18<05:51,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  78%|███████▊  | 390/500 [19:21<05:43,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  78%|███████▊  | 391/500 [19:23<04:49,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  78%|███████▊  | 392/500 [19:26<04:59,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  79%|███████▊  | 393/500 [19:29<05:10,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  79%|███████▉  | 394/500 [19:32<05:15,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  79%|███████▉  | 395/500 [19:35<05:09,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  79%|███████▉  | 396/500 [19:38<05:13,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  79%|███████▉  | 397/500 [19:41<05:11,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  80%|███████▉  | 398/500 [19:44<05:09,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  80%|███████▉  | 399/500 [19:47<04:39,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  80%|████████  | 400/500 [19:50<05:04,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  80%|████████  | 401/500 [19:53<04:58,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  80%|████████  | 402/500 [19:56<04:51,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  81%|████████  | 403/500 [19:59<04:40,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  81%|████████  | 404/500 [20:02<04:48,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  81%|████████  | 405/500 [20:06<05:03,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  81%|████████  | 406/500 [20:08<04:45,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  81%|████████▏ | 407/500 [20:11<04:40,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  82%|████████▏ | 408/500 [20:14<04:32,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  82%|████████▏ | 409/500 [20:17<04:38,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  82%|████████▏ | 410/500 [20:21<04:52,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  82%|████████▏ | 411/500 [20:24<04:30,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  82%|████████▏ | 412/500 [20:27<04:31,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  83%|████████▎ | 413/500 [20:30<04:21,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  83%|████████▎ | 414/500 [20:33<04:26,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  83%|████████▎ | 415/500 [20:36<04:23,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  83%|████████▎ | 416/500 [20:39<04:27,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  83%|████████▎ | 417/500 [20:43<04:24,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  84%|████████▎ | 418/500 [20:46<04:26,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  84%|████████▍ | 419/500 [20:49<04:23,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  84%|████████▍ | 420/500 [20:53<04:20,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  84%|████████▍ | 421/500 [20:56<04:09,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  84%|████████▍ | 422/500 [20:59<04:05,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  85%|████████▍ | 423/500 [21:01<03:46,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  85%|████████▍ | 424/500 [21:05<04:04,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  85%|████████▌ | 425/500 [21:07<03:35,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  85%|████████▌ | 426/500 [21:09<03:24,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  85%|████████▌ | 427/500 [21:12<03:25,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  86%|████████▌ | 428/500 [21:16<03:36,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  86%|████████▌ | 429/500 [21:20<03:52,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  86%|████████▌ | 430/500 [21:23<03:45,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  86%|████████▌ | 431/500 [21:26<03:41,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  86%|████████▋ | 432/500 [21:28<03:07,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  87%|████████▋ | 433/500 [21:31<03:05,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  87%|████████▋ | 434/500 [21:34<03:11,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  87%|████████▋ | 435/500 [21:37<03:16,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  87%|████████▋ | 436/500 [21:40<03:03,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  87%|████████▋ | 437/500 [21:42<02:59,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  88%|████████▊ | 438/500 [21:45<02:55,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  88%|████████▊ | 439/500 [21:48<03:00,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  88%|████████▊ | 440/500 [21:52<03:05,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  88%|████████▊ | 441/500 [21:55<02:57,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  88%|████████▊ | 442/500 [21:58<02:59,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  89%|████████▊ | 443/500 [22:01<02:58,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  89%|████████▉ | 444/500 [22:05<03:03,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  89%|████████▉ | 445/500 [22:08<03:01,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  89%|████████▉ | 446/500 [22:11<02:59,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  89%|████████▉ | 447/500 [22:15<02:57,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  90%|████████▉ | 448/500 [22:18<02:54,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  90%|████████▉ | 449/500 [22:21<02:48,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  90%|█████████ | 450/500 [22:24<02:41,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  90%|█████████ | 451/500 [22:28<02:37,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  90%|█████████ | 452/500 [22:31<02:41,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  91%|█████████ | 453/500 [22:35<02:37,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  91%|█████████ | 454/500 [22:38<02:31,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  91%|█████████ | 455/500 [22:41<02:27,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  91%|█████████ | 456/500 [22:45<02:31,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  91%|█████████▏| 457/500 [22:49<02:29,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  92%|█████████▏| 458/500 [22:51<02:16,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  92%|█████████▏| 459/500 [22:54<02:06,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  92%|█████████▏| 460/500 [22:57<01:57,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  92%|█████████▏| 461/500 [23:00<01:58,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  92%|█████████▏| 462/500 [23:03<01:57,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  93%|█████████▎| 463/500 [23:06<01:56,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  93%|█████████▎| 464/500 [23:09<01:52,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  93%|█████████▎| 465/500 [23:12<01:48,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  93%|█████████▎| 466/500 [23:16<01:51,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  93%|█████████▎| 467/500 [23:19<01:40,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  94%|█████████▎| 468/500 [23:22<01:40,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  94%|█████████▍| 469/500 [23:25<01:38,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  94%|█████████▍| 470/500 [23:29<01:41,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  94%|█████████▍| 471/500 [23:33<01:40,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  94%|█████████▍| 472/500 [23:36<01:35,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  95%|█████████▍| 473/500 [23:38<01:21,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  95%|█████████▍| 474/500 [23:41<01:15,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  95%|█████████▌| 475/500 [23:43<01:08,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  95%|█████████▌| 476/500 [23:46<01:08,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  95%|█████████▌| 477/500 [23:49<01:07,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  96%|█████████▌| 478/500 [23:53<01:05,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  96%|█████████▌| 479/500 [23:56<01:02,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  96%|█████████▌| 480/500 [23:58<00:55,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  96%|█████████▌| 481/500 [24:01<00:55,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  96%|█████████▋| 482/500 [24:04<00:54,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  97%|█████████▋| 483/500 [24:06<00:45,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  97%|█████████▋| 484/500 [24:08<00:36,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  97%|█████████▋| 485/500 [24:10<00:34,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  97%|█████████▋| 486/500 [24:13<00:37,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  97%|█████████▋| 487/500 [24:17<00:36,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  98%|█████████▊| 488/500 [24:19<00:33,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  98%|█████████▊| 489/500 [24:22<00:31,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  98%|█████████▊| 490/500 [24:26<00:30,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  98%|█████████▊| 491/500 [24:28<00:25,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  98%|█████████▊| 492/500 [24:30<00:20,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  99%|█████████▊| 493/500 [24:33<00:18,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  99%|█████████▉| 494/500 [24:36<00:16,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  99%|█████████▉| 495/500 [24:38<00:12,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  99%|█████████▉| 496/500 [24:41<00:10,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions:  99%|█████████▉| 497/500 [24:45<00:08,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions: 100%|█████████▉| 498/500 [24:48<00:05,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions: 100%|█████████▉| 499/500 [24:50<00:02,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Generating Predictions: 100%|██████████| 500/500 [24:53<00:00,  2.99s/it]\n",
            "wmt20-comet-da.tar.gz: 1.79GB [01:59, 15.0MB/s]                            \n",
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.3.5 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/unbabel_comet/wmt20-comet-da/checkpoints/model.ckpt`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0b9716165994bdb9784c462ff4a728a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e9f435cd9024be4b3ebd35ae636a9e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc3f96343c5a456d99dcea0d61b7d144",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6324fef12d048689eed48fac8d713b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Predicting DataLoader 0: 100%|██████████| 63/63 [00:19<00:00,  3.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Score: 2.79056401931734\n",
            "ROUGE Scores: {'rouge1': 0.218234295156334, 'rouge2': 0.0665648739824959, 'rougeL': 0.18146703887937182}\n",
            "Average COMET Score: -1.2487209937945007\n"
          ]
        }
      ],
      "source": [
        "# Generate translations for the test dataset\n",
        "def generate_predictions(test_dataset, model, tokenizer, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for example in tqdm(test_dataset, desc=\"Generating Predictions\"):\n",
        "            input_text = f\"{START_SYMBOL_SOURCE} {example['Source_clean']} {END_SYMBOL_SOURCE} {START_SYMBOL_TARGET}\"\n",
        "            inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_length=96,\n",
        "                num_beams=5,\n",
        "                early_stopping=True\n",
        "            )\n",
        "            prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Metric calculation functions\n",
        "def calculate_bleu(references, predictions):\n",
        "    bleu = sacrebleu.corpus_bleu(predictions, [references])\n",
        "    return bleu.score\n",
        "\n",
        "def calculate_rouge(references, predictions):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = [scorer.score(ref, pred) for ref, pred in zip(references, predictions)]\n",
        "    averaged_scores = {\n",
        "        metric: sum([score[metric].fmeasure for score in rouge_scores]) / len(rouge_scores)\n",
        "        for metric in ['rouge1', 'rouge2', 'rougeL']\n",
        "    }\n",
        "    return averaged_scores\n",
        "\n",
        "def calculate_comet(references, predictions, source_sentences):\n",
        "    model_path = download_model(\"wmt20-comet-da\")  # Download COMET model\n",
        "    comet_model = load_from_checkpoint(model_path)\n",
        "    data = [{\"src\": \"\", \"mt\": pred, \"ref\": ref} for src, pred, ref in zip(source_sentences, predictions, references)]\n",
        "    comet_scores = comet_model.predict(data, batch_size=8, gpus=1 if torch.cuda.is_available() else 0)\n",
        "    return comet_scores[\"scores\"]\n",
        "\n",
        "# Main evaluation function\n",
        "def evaluate_metrics(test_dataset, model, tokenizer):\n",
        "    sources = [example[\"Source_clean\"] for example in test_dataset]\n",
        "    references = [example[\"Target_clean\"] for example in test_dataset]\n",
        "    predictions = generate_predictions(test_dataset, model, tokenizer)\n",
        "\n",
        "    # Calculate metrics\n",
        "    bleu_score = calculate_bleu(references, predictions)\n",
        "    rouge_scores = calculate_rouge(references, predictions)\n",
        "    comet_scores = calculate_comet(references, predictions, sources)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"BLEU Score: {bleu_score}\")\n",
        "    print(f\"ROUGE Scores: {rouge_scores}\")\n",
        "    print(f\"Average COMET Score: {sum(comet_scores) / len(comet_scores)}\")\n",
        "    return {\n",
        "        \"BLEU\": bleu_score,\n",
        "        \"ROUGE\": rouge_scores,\n",
        "        \"COMET\": comet_scores\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "# Assuming test_dataset is a list of dictionaries with \"source\" and \"target\" keys\n",
        "test_dataset = [{\"source\": \"source sentence\", \"target\": \"reference sentence\"}]  # Replace with your test data\n",
        "metrics = evaluate_metrics(dataset['test'].select(range(500)), model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuwthHO2B9iV"
      },
      "outputs": [],
      "source": [
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWAp066iP0R8"
      },
      "outputs": [],
      "source": [
        "# Test with sample sentences\n",
        "sample_sentences = [\n",
        "    \"in an asexual species if you get two different mutations in different creatures a green one and a red one then one has to be better than the other\",\n",
        "    \"He’s sort of a Homer Simpson with fins\",\n",
        "    \"So, if algorithms are going to curate the world for us if they re going to decide what we get to see and what we don t get to see then we need to make sure that they re not just keyed to relevance\",\n",
        "    \"They’re not even autonomous\",\n",
        "    \"there s a marker line called the trim line above our little red illustration there\"\n",
        "\n",
        "]\n",
        "for sample_sentence in sample_sentences:\n",
        "  translated_sentence = translate_sentence(sample_sentence, model, tokenizer)\n",
        "  print(f\"Translated Sentence: {translated_sentence}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0010651988784254b4af63b4faf935d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_579d97ee2a83449a8d45d0f497034c80",
              "IPY_MODEL_a464133b7d4e444eaaecaa75d32f5817",
              "IPY_MODEL_55cceec0a9454eb78a5784f0388e70d8"
            ],
            "layout": "IPY_MODEL_40b0acd17a48459194710c3036220571"
          }
        },
        "086ec1c12e964affb6bcb44631013028": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0be5e33e7fbe4bbf8a11aa1033dbbd6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c94ccd47e5d4497ac86b65159e07057": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f87676e7a8f48249bb894f46e1c56e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1884cae8803345b191f4f8f6b1138183": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_964fe078759241c2849baa34a82c83a4",
            "placeholder": "​",
            "style": "IPY_MODEL_dd3fa43beb2640c49475d461054641ec",
            "value": "Map: 100%"
          }
        },
        "1a5acdf599f6471d8c047ca27a297c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af0c4bb91bb42c6aeec5baf9b9ed02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84b71fff553d40f58073c373bffa06e7",
              "IPY_MODEL_81ff3ea51258414cbfb8b94d4d4b0be4",
              "IPY_MODEL_91c0cf6011a24ab8bbf75635811bfccb"
            ],
            "layout": "IPY_MODEL_3f54a15789ba472c8018e32302d342e4"
          }
        },
        "1ce23bf27af4446eb91732da254e965b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a5acdf599f6471d8c047ca27a297c3a",
            "placeholder": "​",
            "style": "IPY_MODEL_4d0650d624524d3693c06361edb43f5f",
            "value": " 61414/61414 [00:01&lt;00:00, 60763.86 examples/s]"
          }
        },
        "221615f928384afbbc9b196045b0612c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22831f605ab04246b866e3e4c027f776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bddd00754db45bcac5acd0476aa0159",
            "max": 61414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_086ec1c12e964affb6bcb44631013028",
            "value": 61414
          }
        },
        "259e92d2889d4c94a6d4a7871f5c2131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b604a484cb24db4a128f80cf1f323c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b40fcdefdf264425b308339178ef2d59",
            "placeholder": "​",
            "style": "IPY_MODEL_9adf48897e754158a6c485007ae23f69",
            "value": " 15354/15354 [00:04&lt;00:00, 4257.24 examples/s]"
          }
        },
        "3f54a15789ba472c8018e32302d342e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b0acd17a48459194710c3036220571": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb9cdb483b7464bae0d11fb72e3cb10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d0650d624524d3693c06361edb43f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55cceec0a9454eb78a5784f0388e70d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe5abfee92f4beb9f496134eeac9f4d",
            "placeholder": "​",
            "style": "IPY_MODEL_259e92d2889d4c94a6d4a7871f5c2131",
            "value": " 61414/61414 [00:10&lt;00:00, 3906.56 examples/s]"
          }
        },
        "5671049a33aa408080e0f9141ac4126c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579d97ee2a83449a8d45d0f497034c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f87676e7a8f48249bb894f46e1c56e4",
            "placeholder": "​",
            "style": "IPY_MODEL_9f7c2b4c7d494eec9f21d58546990742",
            "value": "Map: 100%"
          }
        },
        "8114e680bc3a4acc874aa64e57d7d8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81ff3ea51258414cbfb8b94d4d4b0be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d181b3359ec04d81a0cad9785c54a404",
            "max": 15354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c94ccd47e5d4497ac86b65159e07057",
            "value": 15354
          }
        },
        "822848f990c44910a4887e2f1e67fd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84b71fff553d40f58073c373bffa06e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de565f0a80a14205a3b1650e0a64169a",
            "placeholder": "​",
            "style": "IPY_MODEL_8114e680bc3a4acc874aa64e57d7d8d3",
            "value": "Map: 100%"
          }
        },
        "866f9d582a5a4c798972e03a8079e99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9fed312d06645648c04d775b0a3a5ca",
              "IPY_MODEL_fbb4ab6f91dd4e7e89bbe73ca4969ad1",
              "IPY_MODEL_3b604a484cb24db4a128f80cf1f323c7"
            ],
            "layout": "IPY_MODEL_0be5e33e7fbe4bbf8a11aa1033dbbd6d"
          }
        },
        "8bddd00754db45bcac5acd0476aa0159": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c0cf6011a24ab8bbf75635811bfccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7bdb4f48463433e8aa1c8fce3fadb18",
            "placeholder": "​",
            "style": "IPY_MODEL_c71e90b5ca284c62896cd62d057b3135",
            "value": " 15354/15354 [00:00&lt;00:00, 61758.48 examples/s]"
          }
        },
        "964fe078759241c2849baa34a82c83a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "981cc9bd46cf4b13b2efedbbcbf4902e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9adf48897e754158a6c485007ae23f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f7c2b4c7d494eec9f21d58546990742": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a464133b7d4e444eaaecaa75d32f5817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb6b9497e0249459f1bbead92b138bd",
            "max": 61414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beb1b0ba09c1447a919eea6212ea0638",
            "value": 61414
          }
        },
        "abb6b9497e0249459f1bbead92b138bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40fcdefdf264425b308339178ef2d59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb1b0ba09c1447a919eea6212ea0638": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c71e90b5ca284c62896cd62d057b3135": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7bdb4f48463433e8aa1c8fce3fadb18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d181b3359ec04d81a0cad9785c54a404": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bf1514b32049bba3c97ff225f9074b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1884cae8803345b191f4f8f6b1138183",
              "IPY_MODEL_22831f605ab04246b866e3e4c027f776",
              "IPY_MODEL_1ce23bf27af4446eb91732da254e965b"
            ],
            "layout": "IPY_MODEL_4bb9cdb483b7464bae0d11fb72e3cb10"
          }
        },
        "dd3fa43beb2640c49475d461054641ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de565f0a80a14205a3b1650e0a64169a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe5abfee92f4beb9f496134eeac9f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9fed312d06645648c04d775b0a3a5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5671049a33aa408080e0f9141ac4126c",
            "placeholder": "​",
            "style": "IPY_MODEL_981cc9bd46cf4b13b2efedbbcbf4902e",
            "value": "Map: 100%"
          }
        },
        "fbb4ab6f91dd4e7e89bbe73ca4969ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221615f928384afbbc9b196045b0612c",
            "max": 15354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_822848f990c44910a4887e2f1e67fd39",
            "value": 15354
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
